# Sanity check for the results from compute_entropy.py
# Yang Xu
# 3/2/2017

library(data.table)
library(ggplot2)
library(lme4)
library(lmerTest)


## Switchboard data trained by cross-validation
dt = fread('data/SWBD_entropy_crossvalidate.csv')

m = lmer(ent ~ globalId + (1|convId), dt)
summary(m)
# globalId    -4.283e-05  3.129e-05  8.168e+04  -1.369    0.171
m = lmer(ent ~ log(globalId) + (1|convId), dt)
summary(m)
# log(globalId) -5.825e-03  1.778e-03  1.295e+05  -3.276  0.00105 **


## BNC data trained by cross-validation
dt = fread('data/BNC_entropy_crossvalidate.csv')

m = lmer(ent ~ globalId + (1|convId), dt)
summary(m)
# globalId    -4.952e-05  1.109e-04  4.158e+04  -0.447    0.655
m = lmer(ent ~ log(globalId) + (1|convId), dt)
summary(m)
# log(globalId) -1.047e-02  2.791e-03  3.570e+04  -3.752 0.000176 ***


## Switchboard data trained from BNC
dt = fread('data/SWBD_entropy_fromBNC.csv')

m = lmer(ent ~ globalId + (1|convId), dt)
summary(m)
# globalId    -3.720e-04  3.272e-05  5.571e+04  -11.37   <2e-16 ***
m = lmer(ent ~ log(globalId) + (1|convId), dt)
summary(m)
# log(globalId) -3.145e-02  1.872e-03  1.119e+05   -16.8   <2e-16 ***

# plot
p = ggplot(dt[globalId<=100,], aes(x=globalId, y=ent)) +
    stat_summary(fun.y = mean, geom = 'line') +
    stat_summary(fun.data = mean_cl_boot, geom = 'ribbon', alpha=.5)


## BNC data trained from Switchboard
dt = fread('data/BNC_entropy_fromSWBD.csv')

m = lmer(ent ~ globalId + (1|convId), dt)
summary(m)
# globalId    -3.283e-04  1.335e-04  3.289e+04   -2.46   0.0139 *
m = lmer(ent ~ log(globalId) + (1|convId), dt)
summary(m)
# log(globalId) -1.898e-02  3.343e-03  2.906e+04  -5.678 1.37e-08 ***


## Switchboard data trained from LMs of same position
dt = fread('data/SWBD_entropy_crossvalidate_samepos.csv')

m = lmer(ent ~ globalId + (1|convId), dt)
summary(m)
# globalId    -4.283e-05  3.129e-05  8.168e+04  -1.369    0.171
m = lmer(ent ~ log(globalId) + (1|convId), dt)
summary(m)
# log(globalId) 3.967e-03  2.124e-03 1.036e+05   1.868   0.0618 .

p = ggplot(dt[globalId<=100,], aes(x=globalId, y=ent)) +
    stat_summary(fun.y = mean, geom = 'line') +
    stat_summary(fun.data = mean_cl_boot, geom = 'ribbon', alpha=.5)


## BNC data trained from LMs of same position
dt = fread('data/BNC_entropy_crossvalidate_samepos.csv')

m = lmer(ent ~ globalId + (1|convId), dt)
summary(m)
# globalId    -2.040e-04  8.937e-05  3.546e+04  -2.283   0.0225 *
m = lmer(ent ~ log(globalId) + (1|convId), dt)
summary(m)
# log(globalId) -9.336e-03  2.242e-03  3.095e+04  -4.165 3.13e-05 ***
p = ggplot(dt[globalId<=100,], aes(x=globalId, y=ent)) +
    stat_summary(fun.y = mean, geom = 'line') +
    stat_summary(fun.data = mean_cl_boot, geom = 'ribbon', alpha=.5)


## SWBD trained from WSJ
dt = fread('data/SWBD_entropy_fromWSJ.csv')

m = lmer(ent ~ globalId + (1|convId), dt)
summary(m)
# globalId    -2.680e-05  2.686e-05  7.969e+04  -0.998    0.318
m = lmer(ent ~ log(globalId) + (1|convId), dt)
summary(m)
# log(globalId) -1.208e-02  1.527e-03  1.283e+05  -7.908 2.66e-15 ***


## BNC trained from WSJ
dt = fread('data/BNC_entropy_fromWSJ.csv')

m = lmer(ent ~ globalId + (1|convId), dt)
summary(m)
# globalId    -1.575e-04  9.340e-05  2.413e+04  -1.686   0.0918 .
m = lmer(ent ~ log(globalId) + (1|convId), dt)
summary(m)
# log(globalId) -9.066e-03  2.336e-03  2.252e+04  -3.882 0.000104 ***


## WSJ trained by cross-validation, using SRILM
dt = fread('data/wsj_entropy.csv')

m = lmer(ent ~ sentId + (1|fileId), dt)
summary(m)
# sentId      7.940e-03  1.215e-03 1.118e+04   6.537 6.55e-11 ***
# Yes, it means that SRILM can correctly replicate the entropy increase reported by Genzel et al 2002 & 2003
p = ggplot(dt, aes(x=sentId, y=ent)) +
    stat_summary(fun.y = mean, geom = 'line') +
    stat_summary(fun.data = mean_cl_boot, geom = 'ribbon', alpha=.5)



## SWBD trained by cross-validation, but with NLTK code and SRILM method
dt = fread('data/results_swbd_srilm_CV.txt')
setnames(dt, c('convId', 'globalId', 'localId', 'ent'))
m = lmer(ent ~ globalId + (1|convId), dt)
summary(m)
# globalId    -1.335e-04  7.006e-05  1.035e+05  -1.905   0.0568 .
# OKay, although we use the same cross-validation code that generates the nltk NgramModel data
# The current data generated by SRILM seem not consistent with it
# Needs to further look into how SRILM computes entropy differs from nltk NgramModel
# Maybe, starting from simpler estimation (e.g., unigram) of informaiton content is a good choice!


## SWBD infocont by unigram frequency
# NOTE: this is bad
dt = fread('data/SWBD_infocont_unifreq.csv')
m = lmer(infoCont ~ globalId + (1|convId), dt)
summary(m)
# globalId    -6.718e-05  5.659e-05  8.945e+04  -1.187    0.235
m = lmer(infoCont ~ globalId + (1|convId), dt[globalId<=100,])
summary(m)
# globalId    -1.179e-03  1.324e-04  1.036e+05  -8.908   <2e-16 ***
m = lmer(infoCont ~ globalId + (1|convId), dt[globalId<=100 & globalId>=25,])
summary(m)
# n.s.
p = ggplot(dt[globalId<=100,], aes(x=globalId, y=infoCont)) +
    stat_summary(fun.y = mean, geom = 'line') +
    stat_summary(fun.data = mean_cl_boot, geom = 'ribbon', alpha=.5)



########
# Check old entropy results, computed from nltk NgramModel
dt = fread('data/results_swbd_nltk_CV.csv')
setnames(dt, c('convId', 'globalId', 'localId', 'ent'))
m = lmer(ent ~ globalId + (1|convId), dt)
summary(m)
# globalId    4.225e-03  4.888e-04 1.036e+05   8.643   <2e-16 ***

dt = fread('data/results_BNC-DEM_CV_fullInfo_copy_new.csv')
setkey(dt, xmlId, divId)
dt[, convId := .GRP, by = .(xmlId, divId)]
m = lmer(ent ~ globalId + (1|convId), dt)
summary(m)
# globalId    1.514e-02  8.835e-04 3.547e+04   17.14   <2e-16 ***

## Old train by bin results
dt = fread('data/results_swbd_nltk_trainByBin.txt')
setnames(dt, c('globalId', 'localId', 'ent'))
summary(lm(ent ~ globalId, dt))
# globalId    0.001531   0.001429   1.071    0.284
